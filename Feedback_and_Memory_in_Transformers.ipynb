{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Feedback and Memory in Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "an71fKAw6td9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74ef3957cc3247559ac94c0c29ef2919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee6d3b1acaee42688b4e47633276cef3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40a6bc1044c1450e817a81aef75fec82",
              "IPY_MODEL_d6213d98a82b4baab47c7e9ccb9584b0"
            ]
          }
        },
        "ee6d3b1acaee42688b4e47633276cef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "40a6bc1044c1450e817a81aef75fec82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ee307f3305c433f8bb60d0d759f584b",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdfd28e18e704d7281df7e0c4559eab2"
          }
        },
        "d6213d98a82b4baab47c7e9ccb9584b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3a82d3135444f74b74b9cd0309f76f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [01:37&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c672fff731a41d483584fcda990ac2b"
          }
        },
        "6ee307f3305c433f8bb60d0d759f584b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdfd28e18e704d7281df7e0c4559eab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3a82d3135444f74b74b9cd0309f76f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c672fff731a41d483584fcda990ac2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7761371d69d94d7a8e8228744b56da2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73b0d782ad024059bace9ff0ebbd45ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b2dabbe2bb94891b6d60f28743c483f",
              "IPY_MODEL_07d19ac4fd9344bbaa2ee6144d4e76dd"
            ]
          }
        },
        "73b0d782ad024059bace9ff0ebbd45ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5b2dabbe2bb94891b6d60f28743c483f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba1b5898bb464fe281ce84632a728ad3",
            "_dom_classes": [],
            "description": "Epoch 2:  69%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 663,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 460,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de1a3784b18847e89a1090090f51e260"
          }
        },
        "07d19ac4fd9344bbaa2ee6144d4e76dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1295ddfae26a447aae4a9eaaf09fccdb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 460/663 [00:38&lt;00:16, 11.94it/s, loss=0.28, v_num=0, val_loss=15.40, epoch_val_accuracy=0.00121, train_loss_step=0.243, train_loss_epoch=0.494]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e10aec780f0f4210b17e411db470dc73"
          }
        },
        "ba1b5898bb464fe281ce84632a728ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de1a3784b18847e89a1090090f51e260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1295ddfae26a447aae4a9eaaf09fccdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e10aec780f0f4210b17e411db470dc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20cec9093fda47a98793340671d3ff43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_70a6f758ae124f5e962f137cf1b62931",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4ffdb7b4848417fbcbce237ddbd5a12",
              "IPY_MODEL_b6891efb52614432bab37417a45024cb"
            ]
          }
        },
        "70a6f758ae124f5e962f137cf1b62931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e4ffdb7b4848417fbcbce237ddbd5a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e44643c60f8a4831a0948b889d2a6599",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 46,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4608320c6097483cb358541dadc11682"
          }
        },
        "b6891efb52614432bab37417a45024cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98298d7ac9e244d1bc192bad27034b48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 46/46 [00:09&lt;00:00, 38.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4c5819100414c97b1cf5e2fd92617a3"
          }
        },
        "e44643c60f8a4831a0948b889d2a6599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4608320c6097483cb358541dadc11682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98298d7ac9e244d1bc192bad27034b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4c5819100414c97b1cf5e2fd92617a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45fe67dbf2dd4390a03409e95e20d9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d8bfb41c4414bc297cb39ea7d9a240e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74bfae2056da4ad59fb62a4e8d49c42d",
              "IPY_MODEL_28585bbf72fb4ff38f7ef22e15c988ae"
            ]
          }
        },
        "5d8bfb41c4414bc297cb39ea7d9a240e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "74bfae2056da4ad59fb62a4e8d49c42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c31c2f070a26487ab131dc19aa839b0c",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 46,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f02a69dd1b08474694b8de579ced5a18"
          }
        },
        "28585bbf72fb4ff38f7ef22e15c988ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7f9c6717bb21454d8df7184351295797",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 46/46 [00:08&lt;00:00, 37.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ea958baa28a4544b9314d1ac57ee6f8"
          }
        },
        "c31c2f070a26487ab131dc19aa839b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f02a69dd1b08474694b8de579ced5a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f9c6717bb21454d8df7184351295797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ea958baa28a4544b9314d1ac57ee6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaswa/feedback-and-memory-in-transformers/blob/main/Feedback_and_Memory_in_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOKvrKmnjpdR"
      },
      "source": [
        "This notebook explores the role of Feedback and Memory in Transformer models. The notebook is based on this paper:\n",
        "\n",
        "*Fan, A., Lavril, T., Grave, E., Joulin, A., & Sukhbaatar, S. (2020). [Addressing Some Limitations of Transformers with Feedback Memory](https://arxiv.org/abs/2002.09402). arXiv preprint arXiv:2002.09402.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wdRGK9PU6MM"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07leXHx2UzmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3cd4b9-1386-4f4e-ee7b-30bd12db390f"
      },
      "source": [
        "# Check GPU Allotment\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 29 09:29:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDICNw5gY80Q"
      },
      "source": [
        "# Install Dependencies\n",
        "!pip -q install pytorch-lightning\n",
        "!pip -q install torchmetrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ_YZTiBVP9V"
      },
      "source": [
        "\"\"\"\n",
        "IMPORTS\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import string\n",
        "import pandas as pd\n",
        "import math\n",
        "import copy\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import torchmetrics\n",
        "\n",
        "# SEED\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lu7lg7WYT_Y"
      },
      "source": [
        "# Understanding the Importance of Feedback and Memory in Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSldJP2Z-9qc"
      },
      "source": [
        "### Top-down vs Bottom-up Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXbmHNfbk3nb"
      },
      "source": [
        "Most of the Deep Neural Network models follow a **Bottom-up processing** approach, where given a stimulus, high-level latent abstract representations are obtained. These representations are then eventually used for some downstream task.\n",
        "\n",
        "On the other hand, **Top-down processing** relies on world-knowledge and previosuly known facts & beliefs in the memory. Feedback and Memory play a very important role in Top-down processing. Given below is a short video by **Khan Academy** explaining the difference between **Bottom-up & Top-down processing**, and their individual importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "M7pG1j8HVGDa",
        "outputId": "01ecc505-9f3c-4e16-ca5f-b6ffb38da224"
      },
      "source": [
        "# Understanding the Role of Feedback and Top-down processing in Cognition & Perception\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\n",
        "    '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aJy5_p_LAhQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aJy5_p_LAhQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDV8MKD0-3YL"
      },
      "source": [
        "### Limitations of Transformers in Sequential Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xnOv0s0DZf2"
      },
      "source": [
        "[Transformer models](http://jalammar.github.io/illustrated-transformer/) are quite scalable due to their parallel processing capabilities. They handle sequential processing by employing a self-attention mechanism over the entire input sequence. While this helps in capturing a (bi-directional) sequential context while processing the input at a given time-step, it blocks the access to high-level abstract representations from the past time-steps. While this still allows the normal Bottom-up processing, there's no scope for Top-down processing. This results in two major limitations of transformers in sequential tasks:\n",
        "\n",
        "\n",
        "1.   **Limited Access to Higher Level Representations:** This allows the transformer model to perform only a limited number of state-updates to the input states.\n",
        "2.   **Maintaining a Belief State:** This doesn't allow the transformer to work with longer sequences, which requires a good memory component.\n",
        "\n",
        "\n",
        "We'll discuss both these limitations in detail by conducting experiments with a representative task for each of them. We'll also probe how introducding a Top-down feedback with memory helps tackle these limitations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4fC_d6LRy4Z"
      },
      "source": [
        "# Feedback Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU8WxenXUHue"
      },
      "source": [
        "![Feedback Transformer](https://raw.githubusercontent.com/rajaswa/feedback-and-memory-in-transformers/main/figures/feedback_transformer.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqfRokY8Uyy8"
      },
      "source": [
        "**Feedback Transformer** addresses both the above mentioned limitations of **Vanilla Transformer** by performing **Sequential Processing**, instead of the usual Parallel Processing of input sequence. This is done by simply changing the **attention-mechanism** in the architecture:\n",
        "\n",
        "1.   ***Self-Attention over Outputs from Previous Layers is Discarded***\n",
        "2.   ***Attention is instead employed over the Memory states from past input-steps***\n",
        "3.   ***Where, Memory states are obtained by a learnable weighted-summation of all the hidden representations for the particular time-step.***\n",
        "\n",
        "This, enables the access to high-level representations across all the layers. This also allows feedback, where a sub-layer can feed itself via memory. While this is essentially a sequential model, it has **key differences with Recurrent Architectures like multi-layered RNNs and LSTMs**. Each layer of these models has recurrent connections to the same layer, but not to higher layers. Morever,  their internal state has a limited capacity determined by the number of layers and their hidden dimension. In contrast, the internal state of a Feedback Transformer is its whole memory, which can grow with the input length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtnLyDRljBgk"
      },
      "source": [
        "\"\"\"\n",
        "FEEDBACK TRANSFORMER UTILITIES\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=400):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class LinearWeightedAvg(nn.Module):\n",
        "    def __init__(self, n_inputs):\n",
        "        super(LinearWeightedAvg, self).__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(n_inputs))\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        res = 0\n",
        "        weights = self.softmax(self.weights)\n",
        "        for emb_idx, emb in enumerate(input):\n",
        "            res += emb * weights[emb_idx]\n",
        "        return res\n",
        "\n",
        "\n",
        "class FeedforwardBlock(nn.Module):\n",
        "    def __init__(self, d_model, dim_feedforward=2048, dropout=0.1, activation=\"gelu\"):\n",
        "        super(FeedforwardBlock, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout_projection = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.dropout_residual = nn.Dropout(dropout)\n",
        "        self.norm_ff = nn.LayerNorm(d_model)\n",
        "        self.dropout_ff = nn.Dropout(dropout)\n",
        "        self.activation = self._get_activation_fn(activation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden_state = self.dropout_projection(\n",
        "            self.activation(self.linear1(x))\n",
        "        )  # projection\n",
        "        ff_output = self.dropout_ff(self.linear2(hidden_state))  # feed-forward\n",
        "        output = x + self.dropout_residual(ff_output)  # residual-connection\n",
        "        output = self.norm_ff(output)\n",
        "        return output\n",
        "\n",
        "    def _get_activation_fn(self, activation):\n",
        "        if activation == \"relu\":\n",
        "            return F.relu\n",
        "        elif activation == \"gelu\":\n",
        "            return F.gelu\n",
        "        raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB63stEIov9X"
      },
      "source": [
        "\"\"\"\n",
        "FEEDBACK TRANSFORMER ENCODER\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class FeedbackTransformerPointwiseEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=2048,\n",
        "        dropout=0.1,\n",
        "        activation=\"gelu\",\n",
        "    ):\n",
        "        super(FeedbackTransformerPointwiseEncoder, self).__init__()\n",
        "\n",
        "        # memory-attention\n",
        "        self.memory_layer_wise_weighting = LinearWeightedAvg(n_inputs=num_layers)\n",
        "        self.mem_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.mem_attn_dropout = nn.Dropout(dropout)\n",
        "        self.mem_attn_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # feedforward\n",
        "        self.feedforward_layers = self._get_clones(\n",
        "            FeedforwardBlock(d_model, dim_feedforward, dropout, activation), num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, src_embed, memory_states, memory_key_padding_mask):\n",
        "        # layer-wise memory-attention and feedforward\n",
        "        layer_wise_outputs = []\n",
        "        memory_states = torch.stack(memory_states)\n",
        "        memory_key_padding_mask = torch.stack(memory_key_padding_mask, dim=0)\n",
        "        output_embed = src_embed\n",
        "\n",
        "        for feedforward in self.feedforward_layers:\n",
        "\n",
        "            # memory-attention\n",
        "            mem_attn_out, _ = self.mem_attn(\n",
        "                query=output_embed, key=memory_states, value=memory_states, key_padding_mask=memory_key_padding_mask\n",
        "            )\n",
        "            output_embed = output_embed + self.mem_attn_dropout(mem_attn_out)\n",
        "            output_embed = self.mem_attn_norm(output_embed)\n",
        "\n",
        "            # feedforward\n",
        "            output_embed = feedforward(output_embed)\n",
        "            layer_wise_outputs.append(output_embed)\n",
        "\n",
        "        # output memory-state for current time-step\n",
        "        output_memory_state = self.memory_layer_wise_weighting(layer_wise_outputs)\n",
        "        return output_embed, output_memory_state\n",
        "\n",
        "    def _get_clones(self, module, N):\n",
        "        return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "\n",
        "class FeedbackTransformerEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        memory_context=16,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=2048,\n",
        "        dropout=0.1,\n",
        "        activation=\"gelu\",\n",
        "    ):\n",
        "        super(FeedbackTransformerEncoder, self).__init__()\n",
        "\n",
        "        self.memory_context = memory_context\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.pointwise_encoder = FeedbackTransformerPointwiseEncoder(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_layers=num_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, src, mask, src_key_padding_mask):\n",
        "        # memory context\n",
        "        bs = src.shape[1]\n",
        "        memory_states = [\n",
        "            torch.zeros(bs, self.d_model).to(src.device)\n",
        "            for i in range(self.memory_context)\n",
        "        ]\n",
        "        memory_key_padding_mask = [True for i in range(self.memory_context)]\n",
        "\n",
        "        # iterate over entire sequence-length\n",
        "        pred_seq_logits = []\n",
        "        for i in range(src.shape[0]):\n",
        "            output_embed, output_memory_state = self.pointwise_encoder(\n",
        "                torch.unsqueeze(src[i], dim=0), memory_states, memory_key_padding_mask*bs\n",
        "            )\n",
        "            pred_seq_logits.append(torch.squeeze(output_embed))\n",
        "            memory_states = [torch.squeeze(output_memory_state)] + memory_states[:-1]\n",
        "            memory_key_padding_mask = [False] + memory_key_padding_mask[:-1]\n",
        "\n",
        "        pred_seq_logits = self.norm(torch.stack(pred_seq_logits))\n",
        "        return pred_seq_logits"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qXhrpMZjP9Z"
      },
      "source": [
        "\"\"\"\n",
        "FEEDBACK TRANSFORMER DECODER\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class FeedbackTransformerPointwiseDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=2048,\n",
        "        dropout=0.1,\n",
        "        activation=\"gelu\",\n",
        "    ):\n",
        "        super(FeedbackTransformerPointwiseDecoder, self).__init__()\n",
        "\n",
        "        # cross-attention encoder-decoder\n",
        "        self.cross_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.cross_dropout = nn.Dropout(dropout)\n",
        "        self.cross_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # memory-attention\n",
        "        self.memory_layer_wise_weighting = LinearWeightedAvg(n_inputs=num_layers)\n",
        "        self.mem_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.mem_attn_dropout = nn.Dropout(dropout)\n",
        "        self.mem_attn_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # feedforward\n",
        "        self.feedforward_layers = self._get_clones(\n",
        "            FeedforwardBlock(d_model, dim_feedforward, dropout, activation), num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, tgt_embed, memory_states, encoder_outputs, memory_key_padding_mask):\n",
        "        # layer-wise memory-attention and feedforward\n",
        "        layer_wise_outputs = []\n",
        "        memory_states = torch.stack(memory_states)\n",
        "        memory_key_padding_mask = torch.stack(memory_key_padding_mask, dim=0)\n",
        "        output_embed = tgt_embed\n",
        "\n",
        "        for feedforward in self.feedforward_layers:\n",
        "\n",
        "            # memory-attention\n",
        "            mem_attn_out, _ = self.mem_attn(\n",
        "                query=output_embed, key=memory_states, value=memory_states, key_padding_mask=memory_key_padding_mask\n",
        "            )\n",
        "            output_embed = output_embed + self.mem_attn_dropout(mem_attn_out)\n",
        "            output_embed = self.mem_attn_norm(output_embed)\n",
        "\n",
        "            # cross-attention to encoder outputs\n",
        "            output_embed2, _ = self.cross_attn(\n",
        "                output_embed, encoder_outputs, encoder_outputs\n",
        "            )\n",
        "            output_embed = output_embed + self.cross_dropout(output_embed2)\n",
        "            output_embed = self.cross_norm(output_embed)\n",
        "\n",
        "            # feedforward\n",
        "            output_embed = feedforward(output_embed)\n",
        "            layer_wise_outputs.append(output_embed)\n",
        "\n",
        "        # output memory-state for current time-step\n",
        "        output_memory_state = self.memory_layer_wise_weighting(layer_wise_outputs)\n",
        "        return output_embed, output_memory_state\n",
        "\n",
        "    def _get_clones(self, module, N):\n",
        "        return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "\n",
        "class FeedbackTransformerDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        memory_context=16,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=2048,\n",
        "        dropout=0.1,\n",
        "        activation=\"gelu\",\n",
        "    ):\n",
        "        super(FeedbackTransformerDecoder, self).__init__()\n",
        "\n",
        "        self.memory_context = memory_context\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.pointwise_decoder = FeedbackTransformerPointwiseDecoder(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_layers=num_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        tgt,\n",
        "        encoder_outputs,\n",
        "        tgt_mask,\n",
        "        memory_mask,\n",
        "        tgt_key_padding_mask,\n",
        "        memory_key_padding_mask,\n",
        "    ):\n",
        "        # memory context\n",
        "        bs = tgt.shape[1]\n",
        "        memory_states = [\n",
        "            torch.zeros(bs, self.d_model).to(tgt.device)\n",
        "            for i in range(self.memory_context)\n",
        "        ]\n",
        "        memory_key_padding_mask = [True for i in range(self.memory_context)]\n",
        "\n",
        "        # iterate over entire sequence-length\n",
        "        pred_seq_logits = []\n",
        "        for i in range(tgt.shape[0]):\n",
        "            output_embed, output_memory_state = self.pointwise_decoder(\n",
        "                torch.unsqueeze(tgt[i], dim=0), memory_states, encoder_outputs, memory_key_padding_mask*bs\n",
        "            )\n",
        "            pred_seq_logits.append(torch.squeeze(output_embed))\n",
        "            memory_states = [torch.squeeze(output_memory_state)] + memory_states[:-1]\n",
        "            memory_key_padding_mask = [False] + memory_key_padding_mask[:-1]\n",
        "\n",
        "        pred_seq_logits = self.norm(torch.stack(pred_seq_logits))\n",
        "        return pred_seq_logits"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RP9BHXji93e"
      },
      "source": [
        "\"\"\"\n",
        "END TO END FEEDBACK TRANSFORMER MODEL\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class FeedbackTransformerModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder_feedback=False,\n",
        "        decoder_feedback=True,\n",
        "        memory_context=16,\n",
        "        input_vocab_size=11,\n",
        "        output_vocab_size=11,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=2048,\n",
        "        dropout=0.1,\n",
        "        max_seq_length=400,\n",
        "        PAD_IDX=10,\n",
        "        activation=\"gelu\",\n",
        "    ):\n",
        "        super(FeedbackTransformerModel, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.PAD_IDX = PAD_IDX\n",
        "\n",
        "        # Embeddings\n",
        "        self.pos_encoder = PositionalEncoding(\n",
        "            d_model, dropout=dropout, max_len=max_seq_length\n",
        "        )\n",
        "        self.src_embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(output_vocab_size, d_model)\n",
        "\n",
        "        # Feedback Transformer\n",
        "        if encoder_feedback:\n",
        "            feedback_encoder = FeedbackTransformerEncoder(\n",
        "                memory_context=memory_context,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_layers=num_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "            )\n",
        "        else:\n",
        "            feedback_encoder = None\n",
        "\n",
        "        if decoder_feedback:\n",
        "            feedback_decoder = FeedbackTransformerDecoder(\n",
        "                memory_context=memory_context,\n",
        "                d_model=d_model,\n",
        "                nhead=nhead,\n",
        "                num_layers=num_layers,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "            )\n",
        "        else:\n",
        "            feedback_decoder = None\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            custom_encoder=feedback_encoder,\n",
        "            custom_decoder=feedback_decoder,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "\n",
        "        self.lm_layer = nn.Linear(d_model, output_vocab_size)\n",
        "\n",
        "    def forward(self, input_seq, output_seq, flatten_lm_output=False):\n",
        "        # Input Sequence (N,S) -> Permuted Input Sequence (S,N)\n",
        "        input_seq = input_seq.permute(1, 0)\n",
        "        output_seq = output_seq.permute(1, 0)\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(\n",
        "            input_seq, output_seq, self.PAD_IDX\n",
        "        )\n",
        "\n",
        "        src_embeddings = self.pos_encoder(\n",
        "            self.src_embedding(input_seq) * math.sqrt(self.d_model)\n",
        "        )\n",
        "        tgt_embeddings = self.pos_encoder(\n",
        "            self.tgt_embedding(output_seq) * math.sqrt(self.d_model)\n",
        "        )\n",
        "\n",
        "        transformer_outputs = self.transformer(\n",
        "            src=src_embeddings,\n",
        "            tgt=tgt_embeddings,\n",
        "            src_mask=src_mask.to(src_embeddings.device),\n",
        "            tgt_mask=tgt_mask.to(tgt_embeddings.device),\n",
        "            src_key_padding_mask=src_padding_mask.to(src_embeddings.device),\n",
        "            tgt_key_padding_mask=tgt_padding_mask.to(tgt_embeddings.device),\n",
        "        )\n",
        "\n",
        "        pred_seq_logits = self.lm_layer(transformer_outputs).permute(1, 0, 2)\n",
        "        if flatten_lm_output:\n",
        "            pred_seq_logits = pred_seq_logits.reshape(-1, self.output_vocab_size)\n",
        "        return pred_seq_logits\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def create_mask(self, src, tgt, PAD_IDX):\n",
        "        src_seq_len = src.shape[0]\n",
        "        tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n",
        "        src_mask = torch.zeros((src_seq_len, src_seq_len)).type(torch.bool)\n",
        "\n",
        "        src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "        tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "\n",
        "        return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLseYTzXLTWx"
      },
      "source": [
        "\"\"\"\n",
        "LIGHTNING MODULE FOR SEQ2SEQ TASKS\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Seq2SeqModel(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.loss = nn.CrossEntropyLoss(ignore_index=0)\n",
        "        self.accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_seq, output_seq = batch\n",
        "        pred_seq_logits = self.model(input_seq, output_seq[:, :-1], flatten_lm_output=True)\n",
        "        loss = self.loss(pred_seq_logits, output_seq[:, 1:].reshape(-1))\n",
        "\n",
        "        self.log(\n",
        "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_seq, output_seq = batch\n",
        "        pred_seq_logits = self.model(input_seq, output_seq[:, :-1], flatten_lm_output=True)\n",
        "        loss = self.loss(pred_seq_logits, output_seq[:, 1:].reshape(-1))\n",
        "\n",
        "        self.log(\n",
        "            \"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
        "        )\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"pred\": pred_seq_logits,\n",
        "            \"ground_truth\": output_seq[:, 1:].reshape(-1),\n",
        "        }\n",
        "\n",
        "    def validation_epoch_end(self, validation_step_outputs):\n",
        "        preds, ground_truths = [], []\n",
        "        for out in validation_step_outputs:\n",
        "            preds += torch.argmax(out[\"pred\"], dim=1).tolist()\n",
        "            ground_truths += out[\"ground_truth\"].tolist()\n",
        "        accuracy = self.accuracy(torch.tensor(preds), torch.tensor(ground_truths))\n",
        "\n",
        "        self.log(\n",
        "            \"epoch_val_accuracy\", accuracy, on_epoch=True, prog_bar=True, logger=True\n",
        "        )\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_seq, output_seq = batch\n",
        "        pred_seq_logits = self.model(input_seq, output_seq[:, :-1], flatten_lm_output=True)\n",
        "        loss = self.loss(pred_seq_logits, output_seq[:, 1:].reshape(-1))\n",
        "\n",
        "        self.log(\n",
        "            \"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
        "        )\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"pred\": pred_seq_logits,\n",
        "            \"ground_truth\": output_seq[:, 1:].reshape(-1),\n",
        "        }\n",
        "\n",
        "    def test_epoch_end(self, test_step_outputs):\n",
        "        preds, ground_truths = [], []\n",
        "        for out in test_step_outputs:\n",
        "            preds += torch.argmax(out[\"pred\"], dim=1).tolist()\n",
        "            ground_truths += out[\"ground_truth\"].tolist()\n",
        "        accuracy = self.accuracy(torch.tensor(preds), torch.tensor(ground_truths))\n",
        "\n",
        "        self.log(\n",
        "            \"epoch_test_accuracy\", accuracy, on_epoch=True, prog_bar=True, logger=True\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-3, weight_decay=1e-5)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode=\"min\", factor=0.5, patience=1\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": scheduler,\n",
        "            \"monitor\": \"epoch_val_accuracy\",\n",
        "        }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4B0rl6gvhw"
      },
      "source": [
        "# COGS Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgB_ukk_vwW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94005b25-972e-4136-9552-6a35eeced0b6"
      },
      "source": [
        "\"\"\"\n",
        "RAW DATA\n",
        "\"\"\"\n",
        "\n",
        "!git clone https://github.com/najoungkim/COGS.git\n",
        "BASE_DIR = \"./COGS/data/\"\n",
        "TRAIN_PATH = str(\"{}train.tsv\".format(BASE_DIR))\n",
        "TRAIN_100_PATH = str(\"{}train_100.tsv\".format(BASE_DIR))\n",
        "VALID_PATH = str(\"{}dev.tsv\".format(BASE_DIR))\n",
        "TEST_PATH = str(\"{}test.tsv\".format(BASE_DIR))\n",
        "GEN_PATH = str(\"{}gen.tsv\".format(BASE_DIR))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'COGS'...\n",
            "remote: Enumerating objects: 264, done.\u001b[K\n",
            "remote: Counting objects: 100% (264/264), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 264 (delta 38), reused 251 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (264/264), 2.45 MiB | 13.28 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbujeRbC15cl"
      },
      "source": [
        "\"\"\"\n",
        "PYTORCH DATASET CLASS\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class COGSDataset(Dataset):\n",
        "    def __init__(self, PATH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.PAD_IDX = 0\n",
        "        self.BOS_IDX = 1\n",
        "        self.EOS_IDX = 2\n",
        "\n",
        "        # load data\n",
        "        (\n",
        "            src_lines,\n",
        "            tgt_lines,\n",
        "            src_vocab,\n",
        "            tgt_vocab,\n",
        "            self.codes,\n",
        "        ) = self.getCOGSParallelData(PATH)\n",
        "\n",
        "        # tokenize data\n",
        "        self.PAD_IDX = 0\n",
        "        self.src_lines_tokenized, self.src_token2id = self.tokenize(\n",
        "            src_lines, src_vocab\n",
        "        )\n",
        "        print(\n",
        "            \"Tokenized Source Lines. {} Unique Tokens in Source Data\".format(\n",
        "                len(self.src_token2id)\n",
        "            )\n",
        "        )\n",
        "        self.tgt_lines_tokenized, self.tgt_token2id = self.tokenize(\n",
        "            tgt_lines, tgt_vocab\n",
        "        )\n",
        "        print(\n",
        "            \"Tokenized Target Lines. {} Unique Tokens in Target Data\".format(\n",
        "                len(self.tgt_token2id)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def getCOGSParallelData(self, PATH):\n",
        "        # read raw file\n",
        "        with open(PATH) as f:\n",
        "            data = f.readlines()\n",
        "\n",
        "        src_vocab, tgt_vocab = set(), set()\n",
        "        src_lines, tgt_lines, codes = [], [], []\n",
        "\n",
        "        for line in data:\n",
        "            source, target, code = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "            src_lines.append(source)\n",
        "            tgt_lines.append(target)\n",
        "            codes.append(code)\n",
        "            src_vocab.update(source.split())\n",
        "            tgt_vocab.update(target.split())\n",
        "\n",
        "        return src_lines, tgt_lines, src_vocab, tgt_vocab, codes\n",
        "\n",
        "    def tokenize(self, lines, vocab):\n",
        "        vocab = list(vocab)\n",
        "        # create dictionary\n",
        "        token2id = {\"[PAD]\": 0, \"[BOS]\": 1, \"[EOS]\": 2}\n",
        "        for i in range(len(vocab)):\n",
        "            token2id[vocab[i]] = i + 3\n",
        "\n",
        "        # tokenize lines\n",
        "        tokenized_lines = []\n",
        "        for line in lines:\n",
        "            tokenized_line = [self.BOS_IDX] + [token2id[item] for item in line.split()] + [self.EOS_IDX]\n",
        "            tokenized_lines.append(tokenized_line)\n",
        "\n",
        "        return tokenized_lines, token2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_lines_tokenized)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        input_seq = torch.tensor(self.src_lines_tokenized[idx])\n",
        "        output_seq = torch.tensor(self.tgt_lines_tokenized[idx])\n",
        "        return input_seq, output_seq\n",
        "\n",
        "    def pad_tensor(self, tensor, max_length):\n",
        "        tensor = torch.cat(\n",
        "            [tensor, torch.zeros(max_length - tensor.shape[0], dtype=torch.int32)],\n",
        "            dim=0,\n",
        "        )\n",
        "        return tensor\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        # find longest sequences\n",
        "        max_len_input = max([sample[0].shape[0] for sample in batch])\n",
        "        max_len_output = max([sample[1].shape[0] for sample in batch])\n",
        "\n",
        "        # pad according to max_length\n",
        "        input_seq = [self.pad_tensor(sample[0], max_len_input) for sample in batch]\n",
        "        output_seq = [self.pad_tensor(sample[1], max_len_output) for sample in batch]\n",
        "\n",
        "        # stack all\n",
        "        input_seq = torch.stack(input_seq, dim=0)\n",
        "        output_seq = torch.stack(output_seq, dim=0)\n",
        "        return input_seq, output_seq"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKPuCf2xtF7T"
      },
      "source": [
        "\"\"\"\n",
        "LIGHTNING DATAMODULE FOR COGS BENCHMARK\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class COGSDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size=32, num_workers=2, use_100=True):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.use_100 = use_100\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            if self.use_100:\n",
        "                self.train_dataset = COGSDataset(PATH=TRAIN_100_PATH)\n",
        "            else:\n",
        "                self.train_dataset = COGSDataset(PATH=TRAIN_PATH)\n",
        "            self.valid_dataset = COGSDataset(PATH=VALID_PATH)\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_dataset = COGSDataset(PATH=TEST_PATH)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=True,\n",
        "            drop_last=True,\n",
        "            collate_fn=self.train_dataset.collate_fn,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=False,\n",
        "            collate_fn=self.valid_dataset.collate_fn,\n",
        "            drop_last=True,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=False,\n",
        "            collate_fn=self.test_dataset.collate_fn,\n",
        "            drop_last=True,\n",
        "        )\n",
        "\n",
        "# INSTANTITATE A DATAMODULE\n",
        "datamodule = COGSDataModule(batch_size=64, num_workers=2, use_100=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwNt7x-bwqAE"
      },
      "source": [
        "\"\"\"\n",
        "TRAINING SETUP FOR COGS BENCHMARK\n",
        "\"\"\"\n",
        "\n",
        "trainer_flags = {\n",
        "    \"amp_backend\": \"native\",\n",
        "    \"benchmark\": False,\n",
        "    \"deterministic\": False,\n",
        "    \"callbacks\": [\n",
        "        ModelCheckpoint(monitor=\"epoch_val_accuracy\"),\n",
        "        EarlyStopping(monitor=\"epoch_val_accuracy\", mode=\"max\", patience=3),\n",
        "    ],\n",
        "    \"gpus\": 1,\n",
        "    \"log_every_n_steps\": 10,\n",
        "    \"logger\": TensorBoardLogger(save_dir=\"logs/\", name=\"cogs_benchmark_logs\"),\n",
        "    \"max_epochs\": 100,\n",
        "    \"progress_bar_refresh_rate\": 20,\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db8QkJNGvXTv"
      },
      "source": [
        "### Vanilla Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "74ef3957cc3247559ac94c0c29ef2919",
            "ee6d3b1acaee42688b4e47633276cef3",
            "40a6bc1044c1450e817a81aef75fec82",
            "d6213d98a82b4baab47c7e9ccb9584b0",
            "6ee307f3305c433f8bb60d0d759f584b",
            "fdfd28e18e704d7281df7e0c4559eab2",
            "a3a82d3135444f74b74b9cd0309f76f5",
            "1c672fff731a41d483584fcda990ac2b",
            "7761371d69d94d7a8e8228744b56da2d",
            "73b0d782ad024059bace9ff0ebbd45ac",
            "5b2dabbe2bb94891b6d60f28743c483f",
            "07d19ac4fd9344bbaa2ee6144d4e76dd",
            "ba1b5898bb464fe281ce84632a728ad3",
            "de1a3784b18847e89a1090090f51e260",
            "1295ddfae26a447aae4a9eaaf09fccdb",
            "e10aec780f0f4210b17e411db470dc73",
            "20cec9093fda47a98793340671d3ff43",
            "70a6f758ae124f5e962f137cf1b62931",
            "e4ffdb7b4848417fbcbce237ddbd5a12",
            "b6891efb52614432bab37417a45024cb",
            "e44643c60f8a4831a0948b889d2a6599",
            "4608320c6097483cb358541dadc11682",
            "98298d7ac9e244d1bc192bad27034b48",
            "a4c5819100414c97b1cf5e2fd92617a3",
            "45fe67dbf2dd4390a03409e95e20d9b4",
            "5d8bfb41c4414bc297cb39ea7d9a240e",
            "74bfae2056da4ad59fb62a4e8d49c42d",
            "28585bbf72fb4ff38f7ef22e15c988ae",
            "c31c2f070a26487ab131dc19aa839b0c",
            "f02a69dd1b08474694b8de579ced5a18",
            "7f9c6717bb21454d8df7184351295797",
            "0ea958baa28a4544b9314d1ac57ee6f8"
          ]
        },
        "id": "UfpwjfqSvZ-f",
        "outputId": "bc8a450d-811d-447e-ee9e-c27b58696aa8"
      },
      "source": [
        "\"\"\"\n",
        "TRAIN SEQ2SEQ VANILLA TRANSFORMER FOR COGS BENCHMARK\n",
        "\"\"\"\n",
        "\n",
        "model = Seq2SeqModel(\n",
        "    model=FeedbackTransformerModel(\n",
        "        encoder_feedback=False,\n",
        "        decoder_feedback=False,\n",
        "        memory_context=8,\n",
        "        input_vocab_size=800,\n",
        "        output_vocab_size=800,\n",
        "        d_model=32,\n",
        "        nhead=4,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=64,\n",
        "        max_seq_length=800,\n",
        "        dropout=0.1,\n",
        "        PAD_IDX=0,\n",
        "        activation=\"gelu\",\n",
        "    )\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(**trainer_flags)\n",
        "trainer.fit(model=model, datamodule=datamodule)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenized Source Lines. 747 Unique Tokens in Source Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenized Target Lines. 687 Unique Tokens in Target Data\n",
            "Tokenized Source Lines. 584 Unique Tokens in Source Data\n",
            "Tokenized Target Lines. 579 Unique Tokens in Target Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name     | Type                     | Params\n",
            "------------------------------------------------------\n",
            "0 | model    | FeedbackTransformerModel | 163 K \n",
            "1 | loss     | CrossEntropyLoss         | 0     \n",
            "2 | accuracy | Accuracy                 | 0     \n",
            "------------------------------------------------------\n",
            "163 K     Trainable params\n",
            "0         Non-trainable params\n",
            "163 K     Total params\n",
            "0.653     Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74ef3957cc3247559ac94c0c29ef2919",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7761371d69d94d7a8e8228744b56da2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20cec9093fda47a98793340671d3ff43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45fe67dbf2dd4390a03409e95e20d9b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdGaJIV5vbiH"
      },
      "source": [
        "\"\"\"\n",
        "TEST SEQ2SEQ VANILLA TRANSFORMER FOR COGS BENCHMARK\n",
        "\"\"\"\n",
        "\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux1yEeZ1vUPu"
      },
      "source": [
        "### Feedback Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXrtJ0m-iKF7"
      },
      "source": [
        "\"\"\"\n",
        "TRAIN SEQ2SEQ FEEDBACK TRANSFORMER FOR COGS BENCHMARK\n",
        "\"\"\"\n",
        "\n",
        "model = Seq2SeqModel(\n",
        "    model=FeedbackTransformerModel(\n",
        "        encoder_feedback=False,\n",
        "        decoder_feedback=True,\n",
        "        memory_context=8,\n",
        "        input_vocab_size=800,\n",
        "        output_vocab_size=800,\n",
        "        d_model=32,\n",
        "        nhead=4,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=64,\n",
        "        max_seq_length=800,\n",
        "        dropout=0.1,\n",
        "        PAD_IDX=0,\n",
        "        activation=\"gelu\",\n",
        "    )\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(**trainer_flags)\n",
        "trainer.fit(model=model, datamodule=datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doVQv8eGiSSw"
      },
      "source": [
        "\"\"\"\n",
        "TEST SEQ2SEQ FEEDBACK TRANSFORMER FOR COGS BENCHMARK\n",
        "\"\"\"\n",
        "\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0OgJCBhvRjH"
      },
      "source": [
        "### Logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbQDMDgfia0X"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an71fKAw6td9"
      },
      "source": [
        "# Sequence Copy & Reverse Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_z7T0wW-8LW"
      },
      "source": [
        "\"\"\"\n",
        "PYTORCH DATASET CLASS\n",
        "\"\"\"\n",
        "\n",
        "class SequenceCopyDataset(Dataset):\n",
        "    def __init__(self, num_samples=10000, max_length=40, reverse=True):\n",
        "        super().__init__()\n",
        "        self.PAD_IDX = 0\n",
        "        self.BOS_IDX = 1\n",
        "        self.EOS_IDX = 2\n",
        "        self.sequence_pairs = self.generate_samples(num_samples, max_length, reverse)\n",
        "\n",
        "    def generate_samples(self, num_samples=1000, max_length=40, reverse=False):\n",
        "        sequence_pairs = []\n",
        "        for i in range(num_samples):\n",
        "            input_sequence = [\n",
        "                random.choice([3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "                for _ in range(max_length)\n",
        "            ]\n",
        "            if reverse:\n",
        "                output_sequence = [self.BOS_IDX] + [\n",
        "                    input_sequence[-1 * i] for i in range(1, max_length + 1)\n",
        "                ] + [self.EOS_IDX]\n",
        "            else:\n",
        "                output_sequence = [self.BOS_IDX] + input_sequence + [self.EOS_IDX]\n",
        "            sequence_pairs.append({\"input\": input_sequence, \"output\": output_sequence})\n",
        "        return sequence_pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequence_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        sample = (\n",
        "            torch.tensor(self.sequence_pairs[idx][\"input\"]),\n",
        "            torch.tensor(self.sequence_pairs[idx][\"output\"]),\n",
        "        )\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXSL1CHPVJ86"
      },
      "source": [
        "\"\"\"\n",
        "LIGHTNING DATAMODULE FOR SEQUENCE COPY & REVERSE TASK\n",
        "\"\"\"\n",
        "\n",
        "class SequenceCopyDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch_size=32,\n",
        "        num_workers=4,\n",
        "        num_samples_train=10000,\n",
        "        num_samples_eval=2000,\n",
        "        max_length_train=40,\n",
        "        max_length_eval=60,\n",
        "        reverse=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_samples_train = num_samples_train\n",
        "        self.num_samples_eval = num_samples_eval\n",
        "        self.max_length_train = max_length_train\n",
        "        self.max_length_eval = max_length_eval\n",
        "        self.reverse = reverse\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.train_dataset = SequenceCopyDataset(\n",
        "                num_samples=self.num_samples_train,\n",
        "                max_length=self.max_length_train,\n",
        "                reverse=self.reverse,\n",
        "            )\n",
        "            self.valid_dataset = SequenceCopyDataset(\n",
        "                num_samples=self.num_samples_eval,\n",
        "                max_length=self.max_length_eval,\n",
        "                reverse=self.reverse,\n",
        "            )\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_dataset = SequenceCopyDataset(\n",
        "                num_samples=self.num_samples_eval,\n",
        "                max_length=self.max_length_eval,\n",
        "                reverse=self.reverse,\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=True,\n",
        "            drop_last=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=False,\n",
        "            drop_last=True,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=False,\n",
        "            drop_last=True,\n",
        "        )\n",
        "\n",
        "# INSTANTITATE A DATAMODULE\n",
        "datamodule = SequenceCopyDataModule(\n",
        "    batch_size=64,\n",
        "    num_workers=2,\n",
        "    num_samples_train=10000,\n",
        "    num_samples_eval=1000,\n",
        "    max_length_train=10,\n",
        "    max_length_eval=50,\n",
        "    reverse=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pttlpEu8-AcT"
      },
      "source": [
        "\"\"\"\n",
        "TRAINING SETUP FOR SEQUENCE COPY & REVERSE TASK\n",
        "\"\"\"\n",
        "\n",
        "trainer_flags = {\n",
        "    \"amp_backend\": \"native\",\n",
        "    \"benchmark\": False,\n",
        "    \"deterministic\": False,\n",
        "    \"callbacks\": [\n",
        "        ModelCheckpoint(monitor=\"epoch_val_accuracy\"),\n",
        "        EarlyStopping(monitor=\"epoch_val_accuracy\", mode=\"max\", patience=3),\n",
        "    ],\n",
        "    \"gpus\": 1,\n",
        "    \"log_every_n_steps\": 10,\n",
        "    \"logger\": TensorBoardLogger(save_dir=\"logs/\", name=\"sequence_copy_reverse_logs\"),\n",
        "    \"max_epochs\": 1,\n",
        "    \"progress_bar_refresh_rate\": 20,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0hBCgkxvFWl"
      },
      "source": [
        "### Vanilla Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13kL4GsevBx5"
      },
      "source": [
        "\"\"\"\n",
        "TRAIN SEQ2SEQ VANILLA TRANSFORMER FOR SEQUENCE COPY & REVERSE TASK\n",
        "\"\"\"\n",
        "\n",
        "model = Seq2SeqModel(\n",
        "    model=FeedbackTransformerModel(\n",
        "        encoder_feedback=False,\n",
        "        decoder_feedback=False,\n",
        "        memory_context=16,\n",
        "        input_vocab_size=13,\n",
        "        output_vocab_size=13,\n",
        "        d_model=128,\n",
        "        nhead=8,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=256,\n",
        "        max_seq_length=203,\n",
        "        dropout=0.1,\n",
        "        PAD_IDX=0,\n",
        "        activation=\"gelu\",\n",
        "    )\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(**trainer_flags)\n",
        "trainer.fit(model=model, datamodule=datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okz-_xJ3vJ01"
      },
      "source": [
        "\"\"\"\n",
        "TEST SEQ2SEQ VANILLA TRANSFORMER FOR SEQUENCE COPY & REVERSE TASK\n",
        "\"\"\"\n",
        "\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7nO0x9qu3Vs"
      },
      "source": [
        "### Feedback Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FGnGwxz-LzS"
      },
      "source": [
        "\"\"\"\n",
        "TRAIN SEQ2SEQ FEEDBACK TRANSFORMER FOR SEQUENCE COPY & REVERSE TASK\n",
        "\"\"\"\n",
        "\n",
        "model = Seq2SeqModel(\n",
        "    model=FeedbackTransformerModel(\n",
        "        encoder_feedback=False,\n",
        "        decoder_feedback=True,\n",
        "        memory_context=16,\n",
        "        input_vocab_size=13,\n",
        "        output_vocab_size=13,\n",
        "        d_model=128,\n",
        "        nhead=8,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=256,\n",
        "        max_seq_length=203,\n",
        "        dropout=0.1,\n",
        "        PAD_IDX=0,\n",
        "        activation=\"gelu\",\n",
        "    )\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(**trainer_flags)\n",
        "trainer.fit(model=model, datamodule=datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pmgkDK8-yw_"
      },
      "source": [
        "\"\"\"\n",
        "TEST SEQ2SEQ FEEDBACK TRANSFORMER FOR SEQUENCE COPY & REVERSE TASK\n",
        "\"\"\"\n",
        "\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9f6EXheu-nw"
      },
      "source": [
        "### Logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2p-fW0b-3-h"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}